{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz0hzpcrI078"
      },
      "source": [
        "## 시작하기 전에\n",
        "\n",
        "CIFAR-10 pretrained model 받아오기\n",
        "1. 이 파일이 존재하는 디렉토리에 git bash를 열고 `git clone https://github.com/WaiNaat/PyTorch_CIFAR10.git` 실행\n",
        "\n",
        "\n",
        "몇 가지 오류를 수정한 PytorchFI 라이브러리 받아오기\n",
        "1. 이 파일이 존재하는 디렉토리에 git bash를 열고 `git clone https://github.com/WaiNaat/pytorchfi.git` 실행\n",
        "\n",
        "CIFAR-10 pretrained weight 받아오기\n",
        "\n",
        "1. https://github.com/huyvnphan/PyTorch_CIFAR10 중간의 구글 드라이브 링크에서 zip 파일을 다운 (약 1기가)\n",
        "2. 압축 해제 후 `state_dicts` 폴더를 `./PyTorch_CIFAR10/cifar10_models` 내부로 옮기기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPE26QlAJDd_",
        "outputId": "a6af3270-2eea-414c-b42f-3264ddb1c722"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "from bitstring import BitArray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSDhkFSUJJYh"
      },
      "outputs": [],
      "source": [
        "import pytorchfi\n",
        "from pytorchfi.core import FaultInjection\n",
        "from pytorchfi.neuron_error_models import random_neuron_location\n",
        "from pytorchfi.weight_error_models import random_weight_location\n",
        "\n",
        "from PyTorch_CIFAR10.cifar10_models.vgg import vgg11_bn, vgg13_bn, vgg16_bn, vgg19_bn\n",
        "from PyTorch_CIFAR10.cifar10_models.resnet import resnet18, resnet34, resnet50\n",
        "from PyTorch_CIFAR10.cifar10_models.densenet import densenet121, densenet161, densenet169\n",
        "from PyTorch_CIFAR10.cifar10_models.mobilenetv2 import mobilenet_v2\n",
        "from PyTorch_CIFAR10.cifar10_models.googlenet import googlenet\n",
        "from PyTorch_CIFAR10.cifar10_models.inception import inception_v3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQp0-9qPJODt"
      },
      "source": [
        "## 설정\n",
        "\n",
        "---\n",
        "\n",
        "`model_name`, `model`: 위 셀의 `PyTorch_CIFAR10.cifar10_models` 에서 `import` 한 것들 중 하나      \n",
        "`layer_type`: `['all']` 또는 `torch.nn.Modules`를 상속하는 클래스명으로 구성된 iterable   \n",
        "`layer_nums`: `['all']` 또는 0 이상의 정수로 구성된 배열    \n",
        "`corrupt_input_images`: `True`로 설정 시 model inference 진행 전, 입력 이미지 자체에도 single bit flip 적용\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75fT2KVaJQxh",
        "outputId": "c4a68f8f-14d5-4253-b3ac-317c1479f086"
      },
      "outputs": [],
      "source": [
        "# 실험 환경 설정\n",
        "experiment_id = 3\n",
        "model_name = \"vgg11_bn\"\n",
        "model = vgg11_bn()\n",
        "save_dir = model_name + '_' + str(experiment_id)\n",
        "\n",
        "seed = 12345678\n",
        "\n",
        "batch_size = 256\n",
        "img_size = 32\n",
        "channels = 3\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "corrupt_input_images = True\n",
        "save_detailed_results = True\n",
        "\n",
        "custom_bit_flip_pos = None\n",
        "layer_type = ['all']\n",
        "layer_nums = ['all']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4772Qy2ZJdw7",
        "outputId": "fc3399c4-a71a-4c6d-dddf-755b02e8e5fe"
      },
      "outputs": [],
      "source": [
        "random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### add_input_layer\n",
        "\n",
        "Identity layer를 맨 앞에 추가해서 input image 자체에 fault injection을 할 수 있도록 함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class add_input_layer(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, model, *args):\n",
        "        super().__init__(*args)\n",
        "        self.input_layer = torch.nn.Identity()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, x):\n",
        "        input = self.input_layer(x)\n",
        "        output = self.model(input)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### custom_single_bit_flip\n",
        "\n",
        "`_single_bit_flip`: IEEE-754 standard를 따르는 부동소수점 값을 `bitstring.BitArray` 라이브러리를 이용해서 single bit flip 수행\n",
        "\n",
        "`reset_log`: 만약 `save_log_list=True`로 설정할 경우 `declare_neuron_fault_injection` 과 inference 사이에 반드시 실행시켜야 함.\n",
        "\n",
        "`neuron_single_bit_flip`: `declare_neuron_fault_injection`의 `function`인자로 넘기는 함수.\n",
        "\n",
        "`weight_single_bit_flip`: `declare_weight_fault_injection`의 `function`인자로 넘기는 함수."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class custom_single_bit_flip(FaultInjection):\n",
        "    def __init__(self, model, batch_size, flip_bit_pos=None, save_log_list=False, **kwargs):\n",
        "        super().__init__(model, batch_size, **kwargs)\n",
        "        self.flip_bit_pos = flip_bit_pos\n",
        "        self.save_log_list = save_log_list\n",
        "\n",
        "        self.log_original_value = []\n",
        "        self.log_original_value_bin = []\n",
        "        self.log_error_value = []\n",
        "        self.log_error_value_bin = []\n",
        "        self.log_bit_pos = []\n",
        "\n",
        "    def reset_log(self):\n",
        "        self.log_original_value = []\n",
        "        self.log_original_value_bin = []\n",
        "        self.log_error_value = []\n",
        "        self.log_error_value_bin = []\n",
        "        self.log_bit_pos = []\n",
        "\n",
        "    def _single_bit_flip(self, orig_value, bit_pos):\n",
        "        # data type 설정\n",
        "        save_type = orig_value.dtype\n",
        "        orig_value = orig_value.cpu().item()\n",
        "        length = None\n",
        "        if save_type == torch.float32:\n",
        "            length = 32\n",
        "        elif save_type == torch.float64:\n",
        "            length = 64\n",
        "        else:\n",
        "            raise AssertionError(f'Unsupported Data Type: {save_type}')\n",
        "\n",
        "        # single bit flip\n",
        "        orig_arr = BitArray(float = orig_value, length = length)\n",
        "        error = list(map(int, orig_arr.bin))\n",
        "        error[bit_pos] = (error[bit_pos] + 1) % 2\n",
        "        error = ''.join(map(str, error))\n",
        "        error = BitArray(bin=error)\n",
        "        new_value = error.float\n",
        "\n",
        "        if self.save_log_list:\n",
        "            self.log_original_value.append(orig_value)\n",
        "            self.log_original_value_bin.append(orig_arr.bin)\n",
        "            self.log_error_value.append(new_value)\n",
        "            self.log_error_value_bin.append(error.bin)\n",
        "            self.log_bit_pos.append(bit_pos)\n",
        "\n",
        "        return torch.tensor(new_value, dtype=save_type)\n",
        "\n",
        "    # structure from pytorchfi/neuron_error_models/single_bit_flip_func/single_bit_flip_signed_across_batch\n",
        "    def neuron_single_bit_flip(self, module, input_val, output):\n",
        "        corrupt_conv_set = self.corrupt_layer\n",
        "        \n",
        "        bits = output.dtype\n",
        "        if bits == torch.float32:\n",
        "            bits = 32\n",
        "        elif bits == torch.float64:\n",
        "            bits = 64\n",
        "        else:\n",
        "            raise AssertionError(f'Unsupported data type {bits}')\n",
        "            \n",
        "        if type(corrupt_conv_set) is list:\n",
        "            inj_list = list(\n",
        "                filter(\n",
        "                    lambda x: corrupt_conv_set[x] == self.current_layer,\n",
        "                    range(len(corrupt_conv_set)),\n",
        "                )\n",
        "            )\n",
        "            for i in inj_list:\n",
        "                self.assert_injection_bounds(index=i)\n",
        "                prev_value = output[self.corrupt_batch[i]][self.corrupt_dim[0][i]][\n",
        "                    self.corrupt_dim[1][i]\n",
        "                ][self.corrupt_dim[2][i]]\n",
        "\n",
        "                rand_bit = random.randint(0, bits - 1) if self.flip_bit_pos is None else self.flip_bit_pos\n",
        "\n",
        "                new_value = self._single_bit_flip(prev_value, rand_bit)\n",
        "\n",
        "                output[self.corrupt_batch[i]][self.corrupt_dim[0][i]][\n",
        "                    self.corrupt_dim[1][i]\n",
        "                ][self.corrupt_dim[2][i]] = new_value\n",
        "\n",
        "        else:\n",
        "            if self.current_layer == corrupt_conv_set:\n",
        "                prev_value = output[self.corrupt_batch][self.corrupt_dim[0]][\n",
        "                    self.corrupt_dim[1]\n",
        "                ][self.corrupt_dim[2]]\n",
        "\n",
        "                rand_bit = random.randint(0, bits - 1)\n",
        "\n",
        "                new_value = self._single_bit_flip(prev_value, rand_bit)\n",
        "\n",
        "                output[self.corrupt_batch][self.corrupt_dim[0]][self.corrupt_dim[1]][\n",
        "                    self.corrupt_dim[2]\n",
        "                ] = new_value     \n",
        "\n",
        "        self.update_layer()\n",
        "        if self.current_layer >= len(self.output_size):\n",
        "            self.reset_current_layer()\n",
        "\n",
        "    def weight_single_bit_flip(self, weight, corrupt_idx):\n",
        "        bits = weight.dtype\n",
        "        if bits == torch.float32:\n",
        "            bits = 32\n",
        "        elif bits == torch.float64:\n",
        "            bits = 64\n",
        "        else:\n",
        "            raise AssertionError(f'Unsupported data type {bits}')\n",
        "\n",
        "        rand_bit = random.randint(0, bits - 1) if self.flip_bit_pos is None else self.flip_bit_pos\n",
        "        orig_value = weight[(corrupt_idx)].item()\n",
        "        error_value = self._single_bit_flip(weight[(corrupt_idx)], rand_bit)\n",
        "\n",
        "        return error_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 모델 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80mibcAZJeIk",
        "outputId": "9210231c-81aa-4a23-e6b8-7409684e29bc"
      },
      "outputs": [],
      "source": [
        "# 모델 설정\n",
        "path = f\"./PyTorch_CIFAR10/cifar10_models/state_dicts/{model_name}.pt\"\n",
        "model.load_state_dict(torch.load(path))\n",
        "\n",
        "if corrupt_input_images:\n",
        "    model = add_input_layer(model)\n",
        "\n",
        "if use_gpu: model.to(device='cuda')\n",
        "\n",
        "#print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-p5YbxQJZw6"
      },
      "source": [
        "## 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjscQaFfJ2Uw",
        "outputId": "bfcaeef9-6139-49e0-b2be-f7f702375167"
      },
      "outputs": [],
      "source": [
        "# Transform statics from https://github.com/huyvnphan/PyTorch_CIFAR10/blob/master/data.py\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.4914, 0.4822, 0.4465], (0.2471, 0.2435, 0.2616))\n",
        "    ]\n",
        ")\n",
        "\n",
        "data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "dataset = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg5D8l5PKZdt"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "W8Ft3-avJ2-B",
        "outputId": "15eacd19-e118-4729-b479-c551acbf0489"
      },
      "outputs": [],
      "source": [
        "# single bit flip을 일으킬 모델 만들기\n",
        "base_fi_model = custom_single_bit_flip(\n",
        "    model = copy.deepcopy(model),\n",
        "    batch_size = batch_size, \n",
        "    input_shape = [channels, img_size, img_size], \n",
        "    use_gpu = use_gpu,\n",
        "    layer_types = layer_type,\n",
        "    flip_bit_pos = custom_bit_flip_pos,\n",
        "    save_log_list = save_detailed_results\n",
        ")\n",
        "\n",
        "#print(base_fi_model.print_pytorchfi_layer_summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iw5GEQi_LLq8"
      },
      "outputs": [],
      "source": [
        "# single bit flip을 수행할 layer 번호 정리\n",
        "if 'all' in layer_nums:\n",
        "    layer_nums = range(base_fi_model.get_total_layers())\n",
        "else:\n",
        "    layer_nums.sort()\n",
        "    while layer_nums and layer_nums[-1] >= base_fi_model.get_total_layers():\n",
        "        layer_nums.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEfYiywpM-ew"
      },
      "outputs": [],
      "source": [
        "# 실험 진행\n",
        "results = []\n",
        "error_logs = []\n",
        "\n",
        "for layer_num in tqdm(layer_nums):\n",
        "    \n",
        "    orig_correct_cnt = 0\n",
        "    orig_corrupt_diff_cnt = 0\n",
        "    batch_idx = -1\n",
        "    \n",
        "    for images, labels in dataset:\n",
        "\n",
        "        batch_idx += 1\n",
        "\n",
        "        if use_gpu:\n",
        "            images = images.to(device='cuda')\n",
        "\n",
        "        # 원본에 inference 진행\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            orig_output = model(images)\n",
        "\n",
        "        # single bit flip 위치 지정\n",
        "        layer_num_list = []\n",
        "        dim1 = []\n",
        "        dim2 = []\n",
        "        dim3 = []\n",
        "\n",
        "        for _ in range(batch_size):\n",
        "            layer, C, H, W = random_neuron_location(base_fi_model, layer=layer_num)\n",
        "\n",
        "            layer_num_list.append(layer)\n",
        "            dim1.append(C)\n",
        "            dim2.append(H)\n",
        "            dim3.append(W)\n",
        "\n",
        "        # corrupted model 만들기\n",
        "        base_fi_model.reset_log()\n",
        "        corrupted_model = base_fi_model.declare_neuron_fault_injection(\n",
        "            batch = [i for i in range(batch_size)],\n",
        "            layer_num = layer_num_list,\n",
        "            dim1 = dim1,\n",
        "            dim2 = dim2,\n",
        "            dim3 = dim3,\n",
        "            function = base_fi_model.neuron_single_bit_flip\n",
        "        )\n",
        "\n",
        "        # corrupted model에 inference 진행\n",
        "        corrupted_model.eval()\n",
        "        with torch.no_grad():\n",
        "            corrupted_output = corrupted_model(images)\n",
        "\n",
        "        # 결과 정리\n",
        "        original_output = torch.argmax(orig_output, dim=1).cpu().numpy()\n",
        "        corrupted_output = torch.argmax(corrupted_output, dim=1).cpu().numpy()\n",
        "        labels = labels.numpy()\n",
        "\n",
        "        # 결과 비교: 원본이 정답을 맞춘 경우 중 망가진 모델이 틀린 경우를 셈\n",
        "        for i in range(batch_size):\n",
        "\n",
        "            if labels[i] == original_output[i]:\n",
        "                orig_correct_cnt += 1\n",
        "\n",
        "                if original_output[i] != corrupted_output[i]:\n",
        "                    orig_corrupt_diff_cnt += 1\n",
        "\n",
        "                    if save_detailed_results:\n",
        "                        log = [\n",
        "                            f'Layer: {layer_num}',\n",
        "                            f'Batch: {batch_idx}',\n",
        "                            f'Position: ({i}, {dim1[i]}, {dim2[i]}, {dim3[i]})',\n",
        "                            f'Original value:  {base_fi_model.log_original_value[i]}',\n",
        "                            f'Original binary: {base_fi_model.log_original_value_bin[i]}',\n",
        "                            f'Flip bit: {base_fi_model.log_bit_pos[i]}',\n",
        "                            f'Error value:     {base_fi_model.log_error_value[i]}',\n",
        "                            f'Error binary:    {base_fi_model.log_error_value_bin[i]}',\n",
        "                            f'Label:        {labels[i]}',\n",
        "                            f'Model output: {corrupted_output[i]}',\n",
        "                            '\\n'\n",
        "                        ]\n",
        "\n",
        "                        error_logs.append('\\n'.join(log))\n",
        "\n",
        "    # 결과 저장\n",
        "    result = f'Layer #{layer_num}: {orig_corrupt_diff_cnt} / {orig_correct_cnt} = {orig_corrupt_diff_cnt / orig_correct_cnt * 100:.4f}%, ' + str(base_fi_model.layers_type[layer_num]).split(\".\")[-1].split(\"'\")[0]\n",
        "    #print(result)\n",
        "    results.append(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ehzl010Q2zX"
      },
      "outputs": [],
      "source": [
        "for result in results:\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZq5n6aoQ5gM"
      },
      "source": [
        "## 결과 파일 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlt1CZGdQ7DR"
      },
      "outputs": [],
      "source": [
        "f = open(save_dir + '.txt', 'w')\n",
        "\n",
        "f.write(base_fi_model.print_pytorchfi_layer_summary())\n",
        "f.write(f'\\n\\n===== Result =====\\nSeed: {seed}\\n')\n",
        "for result in results:\n",
        "    f.write(result + '\\n')\n",
        "\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if save_detailed_results:\n",
        "    f = open(save_dir + '_detailed.txt', 'w')\n",
        "\n",
        "    for error_log in error_logs:\n",
        "        f.write(error_log + '\\n')\n",
        "\n",
        "    f.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "5109d816b82be14675a6b11f8e0f0d2e80f029176ed3710d54e125caa8520dfd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
