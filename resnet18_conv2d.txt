============================ PYTORCHFI INIT SUMMARY ==============================

Layer types allowing injections:
----------------------------------------------------------------------------------
   - Conv2d

Model Info:
----------------------------------------------------------------------------------
   - Shape of input into the model: (3 224 224 )
   - Batch Size: 50
   - CUDA Enabled: True

Layer Info:
----------------------------------------------------------------------------------
Layer #       Layer type  Dimensions         Weight Shape         Output Shape
----------------------------------------------------------------------------------
    0           Conv2d           4        [64, 3, 7, 7]    [1, 64, 112, 112]
    1           Conv2d           4       [64, 64, 3, 3]      [1, 64, 56, 56]
    2           Conv2d           4       [64, 64, 3, 3]      [1, 64, 56, 56]
    3           Conv2d           4       [64, 64, 3, 3]      [1, 64, 56, 56]
    4           Conv2d           4       [64, 64, 3, 3]      [1, 64, 56, 56]
    5           Conv2d           4      [128, 64, 3, 3]     [1, 128, 28, 28]
    6           Conv2d           4     [128, 128, 3, 3]     [1, 128, 28, 28]
    7           Conv2d           4      [128, 64, 1, 1]     [1, 128, 28, 28]
    8           Conv2d           4     [128, 128, 3, 3]     [1, 128, 28, 28]
    9           Conv2d           4     [128, 128, 3, 3]     [1, 128, 28, 28]
   10           Conv2d           4     [256, 128, 3, 3]     [1, 256, 14, 14]
   11           Conv2d           4     [256, 256, 3, 3]     [1, 256, 14, 14]
   12           Conv2d           4     [256, 128, 1, 1]     [1, 256, 14, 14]
   13           Conv2d           4     [256, 256, 3, 3]     [1, 256, 14, 14]
   14           Conv2d           4     [256, 256, 3, 3]     [1, 256, 14, 14]
   15           Conv2d           4     [512, 256, 3, 3]       [1, 512, 7, 7]
   16           Conv2d           4     [512, 512, 3, 3]       [1, 512, 7, 7]
   17           Conv2d           4     [512, 256, 1, 1]       [1, 512, 7, 7]
   18           Conv2d           4     [512, 512, 3, 3]       [1, 512, 7, 7]
   19           Conv2d           4     [512, 512, 3, 3]       [1, 512, 7, 7]
==================================================================================


===== Result =====
Quantization bits: 8
Layer #0: 2606 / 34880 = 7.471330275229358%
Layer #1: 2559 / 34880 = 7.33658256880734%
Layer #2: 2524 / 34880 = 7.236238532110091%
Layer #3: 2533 / 34880 = 7.2620412844036695%
Layer #4: 2524 / 34880 = 7.236238532110091%
Layer #5: 2534 / 34880 = 7.264908256880734%
Layer #6: 2507 / 34880 = 7.187499999999999%
Layer #7: 2532 / 34880 = 7.259174311926605%
Layer #8: 2546 / 34880 = 7.299311926605505%
Layer #9: 2520 / 34880 = 7.224770642201834%
Layer #10: 2535 / 34880 = 7.267775229357798%
Layer #11: 2501 / 34880 = 7.1702981651376145%
Layer #12: 2550 / 34880 = 7.310779816513762%
Layer #13: 2546 / 34880 = 7.299311926605505%
Layer #14: 2537 / 34880 = 7.2735091743119265%
Layer #15: 2532 / 34880 = 7.259174311926605%
Layer #16: 2565 / 34880 = 7.353784403669724%
Layer #17: 2511 / 34880 = 7.198967889908257%
Layer #18: 2542 / 34880 = 7.287844036697249%
Layer #19: 2532 / 34880 = 7.259174311926605%
